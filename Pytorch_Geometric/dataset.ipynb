{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"dataset.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyO4LK6Lm2NLeTdbhfnHbxQd"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"vkiB6BkNlnrx"},"outputs":[],"source":[""]},{"cell_type":"markdown","source":["# PyG Dataset"],"metadata":{"id":"wIUvhr48n-gJ"}},{"cell_type":"markdown","source":["## torch_geometric.datasets\n","* contains a variety of common graph datasets\n","* Each PyG dataset stores a list of *torch_geometric.data.Data* objects, where each torch_geometric.data.Data object represents a graph"],"metadata":{"id":"iLCBWI0YsW3k"}},{"cell_type":"code","source":["# example: load TUDataset dataset\n","from torch_geometric.datasets import TUDataset\n","\n","root = './enzymes'\n","name = 'ENZYMES'\n","# The ENZYMES dataset\n","pyg_dataset= TUDataset(root, name)"],"metadata":{"id":"zPsVjDYQ3EbS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# number of graphs in the dataset\n","len(pyg_dataset)\n","\n","# number of calsses for that dataset\n","pyg_dataset.num_classes\n","\n","# number of features for that dataset\n","pyg_dataset.num_features"],"metadata":{"id":"DrGScFVUlpIG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"bldOVgeSlpKO"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## torch_geometric.data\n","* provides the data handling of graphs in PyTorch tensors.\n","* A data object describing a homogeneous graph. The data object can hold node-level, link-level and graph-level attributes.\n","\n","Attributes:\n","* data.x: Node feature matrix with shape [num_nodes, num_node_features]\n","\n","* data.edge_index: Graph connectivity in COO (coordinate) format with shape [2, num_edges] and type torch.long\n","\n","* data.edge_attr: Edge feature matrix with shape [num_edges, num_edge_features]\n","\n","* data.y: Target to train against (may have arbitrary shape), e.g., node-level targets of shape [num_nodes, *] or graph-level targets of shape [1, *]\n","\n","* data.pos: Node position matrix with shape [num_nodes, num_dimensions]\n","* data.is_undirected()- check if graph is undirected\n","* train_mask (optional)- denotes against which nodes to train\n","* val_mask (optional)- denotes which nodes to use for validation\n","* test_mask (optional)- denotes against which nodes to test"],"metadata":{"id":"d6DM_2PWsX83"}},{"cell_type":"code","source":["# \n","data = pyg_dataset[idx]"],"metadata":{"id":"ha9CLm3ulpM1"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Open Graph Benchmark (OGB)\n","\n","* The Open Graph Benchmark (OGB) is a collection of realistic, large-scale, and diverse benchmark datasets for machine learning on graphs. \n","* Its datasets are automatically downloaded, processed, and split using the OGB Data Loader. \n","* The model performance can then be evaluated by using the OGB Evaluator in a unified manner.\n","* OGB also supports PyG dataset and data classes"],"metadata":{"id":"VlaM6Gy22rgm"}},{"cell_type":"code","source":["# 'ogbn-arxiv' dataset\n","import torch_geometric.transforms as T\n","from ogb.nodeproppred import PygNodePropPredDataset, Evaluator\n","\n","\n","dataset_name = 'ogbn-arxiv'\n","dataset = PygNodePropPredDataset(name=dataset_name,\n","                                  transform=T.ToSparseTensor())\n","data = dataset[0]\n","\n","# Make the adjacency matrix to symmetric (sparse symmetric tensor)\n","data.adj_t = data.adj_t.to_symmetric()\n","\n","\n","# a dictionary of train/valid/test split mask (indices)\n","split_idx = dataset.get_idx_split()\n","\n"],"metadata":{"id":"TCqiHQsf2uzG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch_geometric.transforms as T"],"metadata":{"id":"LUBTq8ozOfPu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from ogb.graphproppred.mol_encoder import AtomEncoder  # embed raw atom\n","\n","evaluator = Evaluator(name='ogbg-molhiv')"],"metadata":{"id":"C6x2SQrE42n4"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Dataloader"],"metadata":{"id":"iBT4D6JYSC0n"}},{"cell_type":"code","source":["from torch_geometric.data import DataLoader\n","\n","# example of train/val/test split, based on fixed masking split\n","train_loader = DataLoader(dataset[split_idx[\"train\"]], batch_size=32, shuffle=True, num_workers=0)\n","valid_loader = DataLoader(dataset[split_idx[\"valid\"]], batch_size=32, shuffle=False, num_workers=0)\n","test_loader = DataLoader(dataset[split_idx[\"test\"]], batch_size=32, shuffle=False, num_workers=0)"],"metadata":{"id":"vxkqrjxUSD_J"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"ZzieG39GC4ZL"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Graph Mini-Batching\n","\n","In order to parallelize the processing of a mini-batch of graphs, PyG combines the graphs into a single disconnected graph data object (*torch_geometric.data.Batch*). \n","\n","*torch_geometric.data.Batch* inherits from *torch_geometric.data.Data* and contains an additional attribute called `batch`. \n","\n","The `batch` attribute is a vector mapping each node to the index of its corresponding graph within the mini-batch:\n","\n","    batch = [0, ..., 0, 1, ..., n - 2, n - 1, ..., n - 1]\n","\n","This attribute is crucial for associating which graph each node belongs to and can be used to e.g. average the node embeddings for each graph individually to compute graph level embeddings. \n","* batch.y\n","* batch.x\n","* batch.batch- batch vector which assigns each node to a specific example.\n","* batch.edge_index"],"metadata":{"id":"RAJ7zb3hSvG3"}},{"cell_type":"markdown","source":["## Global Pooling Layers\n","PyG [global pooling layer](https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#global-pooling-layers) (partial list):\n","* global_add_pool- returns batch-wise graph-level-outputs by adding node features across the node dimension, so that for a single graph $G_i$ its output is computed by\n","* global_mean_pool- returns batch-wise graph-level-outputs by averaging node features across the node dimension, so that for a single graph $G_i$ its output is computed by\n","* global_max_pool- Returns batch-wise graph-level-outputs by taking the channel-wise maximum across the node dimension, so that for a single graph $G_i$ its output is computed by\n","* GlobalAttention- Global soft attention layer from the [“Gated Graph Sequence Neural Networks”](https://arxiv.org/pdf/1511.05493.pdf) paper\n","* Set2Set- The global pooling operator based on iterative content-based attention from the [“Order Matters: Sequence to sequence for sets”](https://arxiv.org/pdf/1511.06391.pdf) paper\n","* GraphMultisetTransformer- The global Graph Multiset Transformer pooling operator from the [“Accurate Learning of Graph Representations with Graph Multiset Pooling”](https://arxiv.org/pdf/2102.11533.pdf) paper"],"metadata":{"id":"ZAW54SIG2zVj"}},{"cell_type":"markdown","source":[""],"metadata":{"id":"w6sfcSnTHQHR"}},{"cell_type":"code","source":[""],"metadata":{"id":"zo84a6CKSvl-"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Cora Dataset\n","* CORA dataset is a citation network benchmark. \n","* In this dataset, nodes correspond to documents and edges correspond to undirected citations.\n","* Each node or document in the graph is assigned a class label and features based on the documents binarized bag-of-words representation. \n","* The Cora graph has 2708 nodes, 5429 edges, 7 prediction classes, and 1433 features per node. "],"metadata":{"id":"XJPz_8_MJiaH"}},{"cell_type":"code","source":[""],"metadata":{"id":"b_sslqfEJkgH"},"execution_count":null,"outputs":[]}]}