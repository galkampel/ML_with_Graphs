{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"GNN_model.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOAzwmLQ9eY2MQo1zZimgDD"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"aoICy13qx7cA"},"outputs":[],"source":[""]},{"cell_type":"markdown","source":["# Creating a Message Passing Layer\n","* There are 3 critcal functions needed to define a PyG Message Passing Layer: `forward`, `message`, and `aggregate`.\n","* The job of a message passing layer is to update the current feature representation or embedding of each node in a graph by propagating and transforming information within the graph. \n","* Overall, the general paradigm of a message passing layers is:\n","    1. pre-processing\n","    2. message passing / propagation\n","    3.post-processing."],"metadata":{"id":"9nXv6PfYzUDy"}},{"cell_type":"markdown","source":["## Forward Function\n","The `forward` function handles the pre and post-processing of node features / embeddings, as well as initiates message passing by calling the `propagate` function. \n","* We can place the logic for updating node embeddings after message passing and within the `forward` function. To be more specific, after information is propagated (message passing), we can further transform the node embeddings outputed by `propagate`. Therefore, the output of `forward` is exactly the node embeddings after one GNN layer.\n","\n"],"metadata":{"id":"6KACry1C1XcI"}},{"cell_type":"markdown","source":["## Propagate Function\n","* The `propagate` function encapsulates the message passing process.\n","* It does so by calling three important functions:\n","    1. `message`\n","    2. `aggregate`\n","    3. `update`\n","\n","```\n","def propagate(edge_index, size=size, x=(x_i, x_j), extra=(extra_i, extra_j)):\n","```\n","Calling `propagate` initiates the message passing process.\n","\n","  - `edge_index` is passed to the forward function and captures the edge structure of the graph.\n","  - `x=(x_i, x_j)` represents the **node features** that will be used in message passing. In order to explain why we pass the tuple `(x_i, x_j)`, we first look at how our edges are represented. For every edge $(i, j) \\in \\mathcal{E}$, we can differentiate $i$ as the source or central node ($x_{central}$) and j as the neighboring node ($x_{neighbor}$). \n","    - $i$- indicates a central node\n","    - $j$- indicates a neighboring node\n","  \n","    Taking the example of message passing above, for a central node $u$ we will aggregate and transform all of the messages associated with the nodes $v$ s.t. $(u, v) \\in \\mathcal{E}$ (i.e. $v \\in \\mathcal{N}_{u}$). Thus we see, the subscripts `_i` and `_j` allow us to specifcally differenciate features associated with central nodes (i.e. nodes  recieving message information) and neighboring nodes (i.e. nodes passing messages). \n","\n","\n","  - `extra=(extra_i, extra_j)` represents additional information that we can associate with each node beyond its current feature embedding. In fact, we can include as many additional parameters of the form `param=(param_i, param_j)` as we would like. Again, we highlight that indexing with `_i` and `_j` allows us to differentiate central and neighboring nodes. \n","\n","  - `size`- the size (N, M) of the assignment matrix in case edge_index is a LongTensor. If set to None, the size will be automatically inferred and assumed to be quadratic. \n","\n","\n","  The output of the `propagate` function is a matrix of node embeddings after the message passing process and has shape $[N, d]$."],"metadata":{"id":"qwfyQmRT9ZZg"}},{"cell_type":"markdown","source":["### Message Function\n","```\n","def message(x_j, ...):\n","```\n","The `message` function is called by propagate and constructs the messages from\n","neighboring nodes $j$ to central nodes $i$ for each edge $(i, j)$ in *edge_index*. This function can take any argument that was initially passed to `propagate`. Furthermore, we can again differentiate central nodes and neighboring nodes by appending `_i` or `_j` to the variable name, .e.g. `x_i` and `x_j`. Looking more specifically at the variables, we have:\n","\n","  - `x_j` represents a matrix of feature embeddings for all neighboring nodes passing their messages along their respective edge (i.e. all nodes $j$ for edges $(i, j) \\in \\mathcal{E}$). Thus, its shape is $[|\\mathcal{E}|, d]$!\n","\n","\n","  Critically, we see that the output of the `message` function is a matrix of neighboring node embeddings ready to be aggregated, having shape $[|\\mathcal{E}|, d]$."],"metadata":{"id":"BSffeg4b_FRO"}},{"cell_type":"markdown","source":["# Aggregate Function\n","```\n","def aggregate(self, inputs, index, dim_size = None):\n","```\n","Lastly, the `aggregate` function is used to aggregate the messages from neighboring nodes. Looking at the parameters we highlight:\n","\n","  - `inputs` represents a matrix of the messages passed from neighboring nodes (i.e. the output of the `message` function).\n","  - `index` has the same shape as `inputs` and tells us the central node that corresponding to each of the rows / messages $j$ in the `inputs` matrix. Thus, `index` tells us which rows / messages to aggregate for each central node.\n","\n","  The output of `aggregate` is of shape $[N, d]$.\n","\n","\n","For additional resources refer to the PyG documentation for implementing custom message passing layers: https://pytorch-geometric.readthedocs.io/en/latest/notes/create_gnn.html"],"metadata":{"id":"oxkkwDwj_LnW"}},{"cell_type":"markdown","source":["# message_and_aggregate\n","* fuses the message() and aggregate() functions into a single computation step), which gets called whenever it is implemented and receives a SparseTensor as input for edge_index"],"metadata":{"id":"63r8uN3GA9Hu"}},{"cell_type":"code","source":["from torch_geometric.nn import MessagePassing\n","from torch_sparse import matmul\n","\n","class GINConv(MessagePassing):\n","    def __init__(self):\n","        super().__init__(aggr=\"add\")\n","\n","    def forward(self, x, edge_index):\n","        out = self.propagate(edge_index, x=x)\n","        return MLP((1 + eps) x + out)\n","\n","    # def message(self, x_j):\n","    #     return x_j\n","\n","    def message_and_aggregate(self, adj_t, x):\n","        return matmul(adj_t, x, reduce=self.aggr)\n","\n","    # this should also work\n","    def message_and_aggregate(self, edge_index, x):\n","        return matmul(edge_index, x, reduce=self.aggr)"],"metadata":{"id":"8KHdbNuSx9e9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"8AtUIlhCx9gG"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Stacking GNN layer"],"metadata":{"id":"Q16-jcP9zMpD"}},{"cell_type":"code","source":["import torch\n","import torch_scatter\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","import torch_geometric.nn as pyg_nn\n","import torch_geometric.utils as pyg_utils\n","\n","from torch import Tensor\n","from typing import Union, Tuple, Optional\n","from torch_geometric.typing import (OptPairTensor, Adj, Size, NoneType,\n","                                    OptTensor)\n","\n","from torch.nn import Parameter, Linear\n","from torch_sparse import SparseTensor, set_diag\n","from torch_geometric.nn.conv import MessagePassing\n","from torch_geometric.utils import remove_self_loops, add_self_loops, softmax\n","\n","class GNNStack(torch.nn.Module):\n","    def __init__(self, input_dim, hidden_dim, output_dim, args, emb=False):\n","        super(GNNStack, self).__init__()\n","        conv_model = self.build_conv_model(args.model_type)\n","        self.convs = nn.ModuleList()\n","        self.convs.append(conv_model(input_dim, hidden_dim))\n","        assert (args.num_layers >= 1), 'Number of layers is not >=1'\n","        for l in range(args.num_layers-1):\n","            self.convs.append(conv_model(args.heads * hidden_dim, hidden_dim))\n","\n","        # post-message-passing\n","        self.post_mp = nn.Sequential(\n","            nn.Linear(args.heads * hidden_dim, hidden_dim), nn.Dropout(args.dropout), \n","            nn.Linear(hidden_dim, output_dim))\n","\n","        self.dropout = args.dropout\n","        self.num_layers = args.num_layers\n","\n","        self.emb = emb\n","\n","    def build_conv_model(self, model_type):\n","        if model_type == 'GraphSage':\n","            return GraphSage\n","        elif model_type == 'GAT':\n","            # When applying GAT with num heads > 1, you need to modify the \n","            # input and output dimension of the conv layers (self.convs),\n","            # to ensure that the input dim of the next layer is num heads\n","            # multiplied by the output dim of the previous layer.\n","            # HINT: In case you want to play with multiheads, you need to change the for-loop that builds up self.convs to be\n","            # self.convs.append(conv_model(hidden_dim * num_heads, hidden_dim)), \n","            # and also the first nn.Linear(hidden_dim * num_heads, hidden_dim) in post-message-passing.\n","            return GAT\n","\n","    def forward(self, data):\n","        x, edge_index, batch = data.x, data.edge_index, data.batch\n","          \n","        for i in range(self.num_layers):\n","            x = self.convs[i](x, edge_index)\n","            x = F.relu(x)\n","            x = F.dropout(x, p=self.dropout,training=self.training)\n","\n","        x = self.post_mp(x)\n","\n","        if self.emb == True:\n","            return x\n","\n","        return F.log_softmax(x, dim=1)\n","\n","    def loss(self, pred, label):\n","        return F.nll_loss(pred, label)"],"metadata":{"id":"P5aTmCNGx9kC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"YkT1C99I38W_"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Scatter\n","Reduces all values from the `src` tensor into `out` at the indices specified in the `index` tensor along a given axis `dim`.\n","\n","* application- aggregation function in the aggregate method from MessagePassing class\n","\n","For each value in src, its output index is specified by its index in src for dimensions outside of dim and by the corresponding value in index for dimension dim. The applied reduction is defined via the reduce argument.\n","\n","* `src` – The source tensor.\n","* `index` – The indices of elements to scatter.\n","* `dim` – The axis along which to index. (default: -1)\n","* `out` – The destination tensor.\n","* `dim_size` – If out is not given, automatically create output with size dim_size at dimension dim. If dim_size is not given, a minimal sized output tensor according to index.max() + 1 is returned.\n","* `reduce` – The reduce operation (\"sum\", \"mul\", \"mean\", \"min\" or \"max\"). (default: \"sum\")\n","\n"],"metadata":{"id":"HvNiYfkB-eZ9"}},{"cell_type":"code","source":["import torch_scatter\n","\n","# out = scatter(src, index, dim=1, reduce=\"sum\")\n","# critical to set dim!\n","torch_scatter.scatter(inputs, index, dim=dim, dim_size=dim_size, reduce=\"mean\")"],"metadata":{"id":"YOTtIFVn38Z4"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Models"],"metadata":{"id":"PciMhSyD38nU"}},{"cell_type":"code","source":["def train(dataset, args):\n","    \n","    print(\"Node task. test set size:\", np.sum(dataset[0]['test_mask'].numpy()))\n","    print()\n","    test_loader = loader = DataLoader(dataset, batch_size=args.batch_size, shuffle=False)\n","\n","    # build model\n","    model = GNNStack(dataset.num_node_features, args.hidden_dim, dataset.num_classes, \n","                            args)\n","    scheduler, opt = build_optimizer(args, model.parameters())\n","\n","    # train\n","    losses = []\n","    test_accs = []\n","    best_acc = 0\n","    best_model = None\n","    for epoch in trange(args.epochs, desc=\"Training\", unit=\"Epochs\"):\n","        total_loss = 0\n","        model.train()\n","        for batch in loader:\n","            opt.zero_grad()\n","            pred = model(batch)\n","            label = batch.y\n","            pred = pred[batch.train_mask]\n","            label = label[batch.train_mask]\n","            loss = model.loss(pred, label)\n","            loss.backward()\n","            opt.step()\n","            total_loss += loss.item() * batch.num_graphs  # we care about #graphs in batch (not #nodes)\n","        total_loss /= len(loader.dataset)\n","        losses.append(total_loss)\n","\n","        if epoch % 10 == 0:\n","          test_acc = test(test_loader, model)\n","          test_accs.append(test_acc)\n","          if test_acc > best_acc:\n","            best_acc = test_acc\n","            best_model = copy.deepcopy(model)\n","        else:\n","          test_accs.append(test_accs[-1])\n","    \n","    return test_accs, losses, best_model, best_acc, test_loader\n","\n","def test(loader, test_model, is_validation=False, save_model_preds=False, model_type=None):\n","    test_model.eval()\n","\n","    correct = 0\n","    # Note that Cora is only one graph!\n","    for data in loader:\n","        with torch.no_grad():\n","            # max(dim=1) returns values, indices tuple; only need indices\n","            pred = test_model(data).max(dim=1)[1]\n","            label = data.y\n","\n","        mask = data.val_mask if is_validation else data.test_mask\n","        # node classification: only evaluate on nodes in test set\n","        pred = pred[mask]\n","        label = label[mask]\n","\n","        if save_model_preds:\n","          print (\"Saving Model Predictions for Model Type\", model_type)\n","\n","          data = {}\n","          data['pred'] = pred.view(-1).cpu().detach().numpy()\n","          data['label'] = label.view(-1).cpu().detach().numpy()\n","\n","          df = pd.DataFrame(data=data)\n","          # Save locally as csv\n","          df.to_csv('CORA-Node-' + model_type + '.csv', sep=',', index=False)\n","            \n","        correct += pred.eq(label).sum().item()\n","\n","    total = 0\n","    for data in loader.dataset:\n","        total += torch.sum(data.val_mask if is_validation else data.test_mask).item()\n","\n","    return correct / total\n","  \n","class objectview(object):\n","    def __init__(self, d):\n","        self.__dict__ = d\n"],"metadata":{"id":"vUzboo-KDh5C"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## GraphSage Implementation\n","\n","For our first GNN layer, we will implement the well known GraphSage ([Hamilton et al. (2017)](https://arxiv.org/abs/1706.02216)) layer! \n","\n","For a given *central* node $v$ with current embedding $h_v^{l-1}$, the message passing update rule to tranform $h_v^{l-1} \\rightarrow h_v^l$ is as follows: \n","\n","\\begin{equation}\n","h_v^{(l)} = W_l\\cdot h_v^{(l-1)} + W_r \\cdot AGG(\\{h_u^{(l-1)}, \\forall u \\in N(v) \\})\n","\\end{equation}\n","\n","where $W_1$ and $W_2$ are learanble weight matrices and the nodes $u$ are *neighboring* nodes. Additionally, we use mean aggregation for simplicity:\n","\n","\\begin{equation}\n","AGG(\\{h_u^{(l-1)}, \\forall u \\in N(v) \\}) = \\frac{1}{|N(v)|} \\sum_{u\\in N(v)} h_u^{(l-1)}\n","\\end{equation}\n","\n","One thing to note is that we're adding a **skip connection** to our GraphSage implementation through the term $W_l\\cdot h_v^{(l-1)}$. \n","\n","Lastly, $\\ell$-2 normalization of the node embeddings is applied after each iteration."],"metadata":{"id":"Du1WgAJq3-WH"}},{"cell_type":"code","source":["from torch_geometric.nn.conv import MessagePassing\n","\n","class GraphSage(MessagePassing):\n","    \n","    def __init__(self, in_channels, out_channels, normalize = True,\n","                 bias = False, **kwargs):  \n","        super(GraphSage, self).__init__(**kwargs)\n","\n","        self.in_channels = in_channels\n","        self.out_channels = out_channels\n","        self.normalize = normalize\n","\n","        self.lin_l = nn.Linear(self.in_channels, self.out_channels, bias=True)\n","        self.lin_r = nn.Linear(self.in_channels, self.out_channels, bias=True)\n","\n","        self.reset_parameters()\n","\n","    def reset_parameters(self):\n","        self.lin_l.reset_parameters()\n","        self.lin_r.reset_parameters()\n","\n","    def forward(self, x, edge_index, size = None):\n","        \"\"\" GraphSAGE forward pass\n","        \n","        Parameters\n","        ----------\n","        x : torch.FloatTensor\n","            nodes hidden representation of shape (N, hidden_dim)\n","\n","        edge_index : torch.LongTensor/torch_sparse.SparseTensor\n","            defines the underlying graph connectivity/message passing flow\n","\n","\n","        size (optional) : tuple\n","            The size (N, M) of the assignment matrix in case edge_index is a LongTensor.\n","            This argument is ignored in case edge_index is a torch_sparse.SparseTensor\n","\n","        Returns\n","        -------\n","        torch.FloatTensor\n","            node embeddings of nodes in the batch\n","        \"\"\"\n","\n","        out = self.propagate(edge_index, x=(x, x))  # get aggregated output using propage function\n","        out = self.lin_r(out)\n","        out += self.lin_l(x)  # skip connection\n","        if self.normalize:\n","            out = torch.nn.functional.normalize(out, p=2.0, dim=1)\n","\n","        return out\n","\n","    def message(self, x_j):\n","        \"\"\" GraphSAGE message\n","\n","        Paramerters\n","        -----------\n","        x_j : torch.FloatTensor\n","            x_i's neighbors' hidden representation (E, hidden_dim)\n","        \n","        Returns\n","        -------\n","        torch.FloatTensor\n","            message of node x_i before aggregation\n","\n","        \"\"\"\n","\n","        out = x_j  # the message is the neighbor's (previous) state\n","\n","        return out\n","\n","    def aggregate(self, inputs, index, dim_size = None):\n","        \"\"\" Aggregate messages from all neighbors based on index\n","\n","        Parameters\n","        ----------\n","        inputs :  totch.LongTensor\n","            Inputs to aggregate, i.e. message representations from neighbors\n","\n","        index : torch.LongTensor\n","             The indices of elements to scatter (aggregate by index)\n","\n","        dim_size (optional): int\n","            Output with size dim_size at dimension dim\n","\n","        Returns\n","        -------\n","        torch.FloatTensor\n","            Final aggregated representation of a message\n","        \"\"\"\n","\n","        out = None\n","\n","        # The axis along which to index number of nodes.\n","        node_dim = self.node_dim\n","\n","        out = torch_scatter.scatter(inputs, index, dim=node_dim, dim_size=dim_size, reduce=\"mean\")\n","\n","        return out\n"],"metadata":{"id":"iH-uYA8sKVHB"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## GAT Implementation\n","\n","Attention mechanisms have become the state-of-the-art in many sequence-based tasks such as machine translation and learning sentence representations. One of the major benefits of attention-based mechanisms is their ability to focus on the most relevant parts of the input to make decisions. In this problem, we will see how attention mechanisms can be used to perform node classification over graph-structured data through the usage of Graph Attention Networks (GATs) ([Veličković et al. (2018)](https://arxiv.org/abs/1710.10903)).\n","\n","The building block of the Graph Attention Network is the graph attention layer, which is a variant of the aggregation function. Let $N$ be the number of nodes and $F$ be the dimension of the feature vector for each node. The input to each graph attentional layer is a set of node features: $\\mathbf{h} = \\{\\overrightarrow{h_1}, \\overrightarrow{h_2}, \\dots, \\overrightarrow{h_N}$\\}, $\\overrightarrow{h_i} \\in R^F$. The output of each graph attentional layer is a new set of node features, which may have a new dimension $F'$: $\\mathbf{h'} = \\{\\overrightarrow{h_1'}, \\overrightarrow{h_2'}, \\dots, \\overrightarrow{h_N'}\\}$, with $\\overrightarrow{h_i'} \\in \\mathbb{R}^{F'}$.\n","\n","We will now describe how this transformation is performed for each graph attention layer. First, a shared linear transformation parametrized by the weight matrix $\\mathbf{W} \\in \\mathbb{R}^{F' \\times F}$ is applied to every node. \n","\n","Next, we perform self-attention on the nodes. We use a shared attention function $a$:\n","\\begin{equation} \n","a : \\mathbb{R}^{F'} \\times \\mathbb{R}^{F'} \\rightarrow \\mathbb{R}.\n","\\end{equation}\n","\n","that computes the attention coefficients capturing the importance of node $j$'s features to node $i$:\n","\\begin{equation}\n","e_{ij} = a(\\mathbf{W_l}\\overrightarrow{h_i}, \\mathbf{W_r} \\overrightarrow{h_j})\n","\\end{equation}\n","\n","The most general formulation of self-attention allows every node to attend to all other nodes which drops all structural information. However, to utilize graph structure in the attention mechanisms, we use **masked attention**. In masked attention, we only compute attention coefficients $e_{ij}$ for nodes $j \\in \\mathcal{N}_i$ where $\\mathcal{N}_i$ is some neighborhood of node $i$ in the graph.\n","\n","To easily compare coefficients across different nodes, we normalize the coefficients across $j$ using a softmax function:\n","\\begin{equation}\n","\\alpha_{ij} = \\text{softmax}_j(e_{ij}) = \\frac{\\exp(e_{ij})}{\\sum_{k \\in \\mathcal{N}_i} \\exp(e_{ik})}\n","\\end{equation}\n","\n","For this problem, our attention mechanism $a$ will be a single-layer feedforward neural network parametrized by a weight vectors $\\overrightarrow{a_l} \\in \\mathbb{R}^{F'}$ and $\\overrightarrow{a_r} \\in \\mathbb{R}^{F'}$, followed by a LeakyReLU nonlinearity (with negative input slope 0.2). Let $\\cdot^T$ represent transposition and $||$ represent concatenation. The coefficients computed by our attention mechanism may be expressed as:\n","\n","\\begin{equation}\n","\\alpha_{ij} = \\frac{\\exp\\Big(\\text{LeakyReLU}\\Big(\\overrightarrow{a_l}^T \\mathbf{W_l} \\overrightarrow{h_i} + \\overrightarrow{a_r}^T\\mathbf{W_r}\\overrightarrow{h_j}\\Big)\\Big)}{\\sum_{k\\in \\mathcal{N}_i} \\exp\\Big(\\text{LeakyReLU}\\Big(\\overrightarrow{a_l}^T \\mathbf{W_l} \\overrightarrow{h_i} + \\overrightarrow{a_r}^T\\mathbf{W_r}\\overrightarrow{h_k}\\Big)\\Big)}\n","\\end{equation}\n","\n","For the following questions, we denote `alpha_l` = $\\alpha_l = [...,\\overrightarrow{a_l}^T \\mathbf{W_l} \\overrightarrow{h_i},...] \\in \\mathcal{R}^n$ and `alpha_r` = $\\alpha_r = [..., \\overrightarrow{a_r}^T \\mathbf{W_r} \\overrightarrow{h_j}, ...] \\in \\mathcal{R}^n$.\n","\n","\n","At every layer of GAT, after the attention coefficients are computed for that layer, the aggregation function can be computed by a weighted sum of neighborhood messages, where weights are specified by $\\alpha_{ij}$.\n","\n","Now, we use the normalized attention coefficients to compute a linear combination of the features corresponding to them. These aggregated features will serve as the final output features for every node.\n","\n","\\begin{equation}\n","h_i' = \\sum_{j \\in \\mathcal{N}_i} \\alpha_{ij} \\mathbf{W_r} \\overrightarrow{h_j}.\n","\\end{equation} \n","\n","### Multi-Head Attention\n","To stabilize the learning process of self-attention, we use multi-head attention. To do this we use $K$ independent attention mechanisms, or ``heads`` compute output features as in the above equations. Then, we concatenate these output feature representations:\n","\n","\\begin{equation}\n","    \\overrightarrow{h_i}' = ||_{k=1}^K \\Big(\\sum_{j \\in \\mathcal{N}_i} \\alpha_{ij}^{(k)} \\mathbf{W_r}^{(k)} \\overrightarrow{h_j}\\Big)\n","\\end{equation}\n","\n","where $||$ is concentation, $\\alpha_{ij}^{(k)}$ are the normalized attention coefficients computed by the $k$-th attention mechanism $(a^k)$, and $\\mathbf{W}^{(k)}$ is the corresponding input linear transformation's weight matrix. Note that for this setting, $\\mathbf{h'} \\in \\mathbb{R}^{KF'}$."],"metadata":{"id":"-Ns9GByrLDDn"}},{"cell_type":"code","source":["class GAT(MessagePassing):\n","\n","    def __init__(self, in_channels, out_channels, heads = 2,\n","                 negative_slope = 0.2, dropout = 0., **kwargs):\n","        super(GAT, self).__init__(node_dim=0, **kwargs)\n","\n","        self.in_channels = in_channels\n","        self.out_channels = out_channels\n","        self.heads = heads\n","        self.negative_slope = negative_slope\n","        self.dropout = dropout\n","\n","        self.lin_l = None\n","        self.lin_r = None\n","        self.att_l = None\n","        self.att_r = None\n","\n","        self.lin_l = nn.Linear(in_channels, self.heads * out_channels)\n","\n","        self.lin_r = self.lin_l\n","\n","        self.att_l = Parameter(torch.randn(self.heads, out_channels), requires_grad=True)\n","        self.att_r = Parameter(torch.randn(self.heads, out_channels), requires_grad=True)\n","\n","        self.reset_parameters()\n","\n","    def reset_parameters(self):\n","        nn.init.xavier_uniform_(self.lin_l.weight)\n","        nn.init.xavier_uniform_(self.lin_r.weight)\n","        nn.init.xavier_uniform_(self.att_l)\n","        nn.init.xavier_uniform_(self.att_r)\n","\n","    def forward(self, x, edge_index, size = None):\n","        \"\"\"GAT layer forward pass\n","\n","        Parameters\n","        ----------\n","        x : torch.FloatTensor\n","            node embedding matrix (N, C)\n","        \n","        edge_index : torch.LongTensor/torch_sparse.SparseTensor\n","            defines the underlying graph connectivity/message passing flow\n","            shape: (2, E)\n","\n","        size (optional) : tuple\n","            The size (N, M) of the assignment matrix in case edge_index is a LongTensor.\n","            This argument is ignored in case edge_index is a torch_sparse.SparseTensor\n","\n","        Returns\n","        -------\n","        torch.FloatTensor\n","            node embeddings of nodes in the batch\n","\n","        \"\"\"\n","        \n","        H, C = self.heads, self.out_channels\n","\n","        x_i_embed = self.lin_l(x).view(-1, H, C)  # source node representation  (N, H, C)\n","        x_j_embed = self.lin_r(x).view(-1, H, C)  # target node representation  (N, H, C)\n","        alpha_l = (x_i_embed * self.att_l).sum(-1)  # (N, H)  (alpha for each node v and head h)\n","        alpha_r = (x_j_embed * self.att_r).sum(-1)  # (N, H)  (alpha for each node neighbor u and head h)\n","        out = self.propagate(edge_index, x=(x_i_embed, x_j_embed), alpha=(alpha_l, alpha_r))  # get aggregated output using propage function\n","        out = out.view(-1, H * C)\n","\n","        return out\n","\n","\n","    def message(self, x_j, alpha_j, alpha_i, index, ptr, size_i):\n","        \"\"\" GAT message\n","\n","        Paramerters\n","        -----------\n","        x_j : torch.FloatTensor\n","            x_i's neighbors' hidden representation (E, H, C)  (C- hidden dim)\n","\n","        alpha_j : torch.FloatTensor\n","            pre-message representation of node neighbor j (before applying leaky relu and softmax)\n","            shape: (E, H)\n","\n","        alpha_i : torch.FloatTensor\n","            pre-message representation message of node i (before applying leaky relu and softmax)\n","            shape: (E, H)\n","\n","        index : torch.LongTensor/torch_sparse.SparseTensor\n","            defines the underlying graph connectivity/message passing flow\n","            for softmax (normalize by node's neighbors)\n","            shape: (E, 2)\n","\n","        ptr : LongTensor (optional)\n","            If given, computes the softmax based on sorted inputs in CSR representation.\n","\n","        size_i : \n","        \n","        Returns\n","        -------\n","        torch.FloatTensor\n","            message of node x_i before aggregation\n","\n","        \"\"\"\n","        e_ij = F.leaky_relu(alpha_i + alpha_j, negative_slope=self.negative_slope)\n","        if ptr:\n","            alpha_ij = softmax(ptr, index)   # softmax normalized by neighborhood\n","        else:\n","            alpha_ij = softmax(e_ij, index)  # softmax normalized by neighborhood\n","\n","        # apply dropout on attention weights\n","        alpha_ij = F.dropout(alpha_ij, self.dropout, training=self.training)  #   or (E, H)?\n","        out = x_j * alpha_ij.unsqueeze(-1)  # use unsqueeze for broadcasting  (E, H, C)\n","\n","        return out\n","\n","\n","    def aggregate(self, inputs, index, dim_size = None):\n","        \"\"\" Aggregate messages from all neighbors based on index\n","\n","        Parameters\n","        ----------\n","        inputs :  totch.LongTensor\n","            Inputs to aggregate, i.e. message representations from neighbors\n","\n","        index : torch.LongTensor\n","             The indices of elements to scatter (aggregate by index)\n","\n","        dim_size (optional): int\n","            Output with size dim_size at dimension dim\n","\n","        Returns\n","        -------\n","        torch.FloatTensor\n","            Final aggregated representation of a message\n","        \"\"\"\n","        node_dim = self.node_dim\n","        out = torch_scatter.scatter(inputs, index, dim=node_dim, dim_size=dim_size, reduce=\"sum\")\n","    \n","        return out"],"metadata":{"id":"dO8IallNjje_"},"execution_count":null,"outputs":[]}]}