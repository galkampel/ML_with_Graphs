{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"basics.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMYEcc7wJjTdsiusHQR02jS"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# DeepSNAP Overview\n"," a Python library to assist efficient deep learning on graphs.\n"," * supports flexible graph manipulation, standard pipeline, heterogeneous graphs and simple API.\n","\n"," 1. DeepSNAP is easy to be used for the sophisticated graph manipulations, such as feature computation, pretraining, subgraph extraction etc. during/before the training. \n"," 2. In most frameworks, standard pipelines for node, edge, link, graph-level tasks under inductive or transductive settings are left to the user to code. In practice, there are additional design choices involved (such as how to split dataset for link prediction). DeepSNAP provides such a standard pipeline that greatly saves repetitive coding efforts, and enables fair comparision for models.\n"," 3. Many real-world graphs are heterogeneous graphs. But packages support for heterogeneous graphs, including data storage and flexible message passing, is lacking. DeepSNAP provides an efficient and flexible heterogeneous graph that supports both the node and edge heterogeneity."],"metadata":{"id":"rEol7YRlak3B"}},{"cell_type":"markdown","source":["# 1) DeepSNAP Heterogeneous Graph\n","\n","\n","In DeepSNAP we have three levels of attributes:\n","* **node level** attributes- including `node_feature` and `node_label`.\n","* **edge level** attributes including `edge_feature` and `edge_label`.\n","* **graph level** attributes including `graph_feature` and `graph_label`.\n","\n","\n","DeepSNAP extends its traditional graph representation to include heterogeneous graphs by including the following graph property features:  \n","* `node_feature`: The feature of each node (`torch.tensor`)\n","* `edge_feature`: The feature of each edge (`torch.tensor`)\n","* `node_label`: The label of each node (`int`)\n","* `node_type`: The node type of each node (`string`)\n","* `edge_type`: The edge type of each edge (`string`)\n","\n","where the key **new** features are `node_type` and `edge_type`, which enables us to perform heterogenous message passing.\n"],"metadata":{"id":"oh1-N0XicvEM"}},{"cell_type":"markdown","source":["## Transform NetworkX object G into a deepsnap.hetero_graph.HeteroGraph\n","* G- networkx object with the following aattributes:\n","    * node attributes:\n","        * node_feature (torch.tensor)\n","        * node_label (int)\n","        * node_type (str)\n","    * edge attributes:\n","        * edge_feature (torch.tensor), optional\n","        * edge_labe (int), optional\n","        * edge_type (str)"],"metadata":{"id":"c8oLfNB_uMAT"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"vi-_Gm0sajTs"},"outputs":[],"source":["from deepsnap.hetero_graph import HeteroGraph\n","\n","hete = HeteroGraph(G)"]},{"cell_type":"markdown","source":["* hete.node_types- list of all node types\n","\n","* hete.num_nodes()- a dictionary (key=node_type, value=#nodes of corresponding type)\n","    * hete.num_nodes(\\<node_type\\>)- #nodes of type \\<node_type\\>\n","\n","\n","\n","* hete.node_label- a dictionary of node_type and all corresponding nodes (with same type)\n","    * key- node_type\n","    * value- a tensor of all nodes with the corresponding node type (torch.Tensor)\n","\n","* hete.node_label_index- a dictionary of node_type and all corresponding nodes' indexes\n","    * key- node_type\n","    * value- a tensor of all nodes with the corresponding node indexes (torch.Tensor)\n","    \n","    (each type has its own indexing)\n","\n","* heter.num_node_labels()- a dictionary where key=node_tpye, value=#nodes with the corresponding label (int)\n","    * heter.num_node_features(\\<node_label\\>)- get #nodes with the corresponding \\<node_label\\> (int)\n","\n","\n","* heter.num_node_features()- a dictionary where key=node_tpye, value=#nodes with the corresponding type (int)\n","    * heter.num_node_features(\\<node_type\\>)- get #nodes with the corresponding \\<node_type\\> (int)\n"],"metadata":{"id":"Np-HdwgUv_n0"}},{"cell_type":"code","source":["hete.node_types\n","\n","hete.node_label\n","\n","hete.node_label_index"],"metadata":{"id":"JURXxWnJ9k-j"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":[""],"metadata":{"id":"tsqbuhK6AZxY"}},{"cell_type":"code","source":["# get all nodes' indexes with node_type <node_type> (tensor) from specific graph\n","# .tolist() convert tensor to list\n","\n","n0 = hete._convert_to_graph_index(dataset[k].node_label_index[ <node_type>],  <node_type>).tolist()"],"metadata":{"id":"b_tRbe3DAaMZ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Messages\n","###  Heterogenous Message Types\n","* When applying message passing in heterogenous graphs, we seperately apply message passing over each message type.\n","    *  different message types for the different `node_type` and `edge_type` combinations\n","* messages are viewed as $(\\text{src}, \\text{relation}, \\text{dest})$ and in DeepSNAP: $\\big (node_i^{\\text{type}_i}, edge_{i,j}^{\\text{type}_{i,j}}, node_j^{\\text{type}_j} \\big )$\n","\n","* hete.message_types- list of all message types (message = (src_type, relation, dst_type))\n","*  hete.edge_type - a dictionary, where\n","    * key=message type \n","    * value= list of edges for the correspoding message (same edge_type)\n","\n","* hetero_graph.num_edges()- a dictionary (key=message_type, value=#edges of corresponding type)\n","    * message = (src node_type, relation, dst node_type)\n","    * hete.num_nodes(\\<msg_type\\>)- #edges of type \\<edge_type\\>"],"metadata":{"id":"uJCPlN_f1O8_"}},{"cell_type":"code","source":["# get list of all message types\n","hete.message_types\n","\n","# count #edges for each message type\n","message_type_edges = [(msg_type, len(edges)) for msg_type, edges in hete.edge_type.items()]"],"metadata":{"id":"bHD_qGGoakhn"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Message Passing Layer\n","\n","* Heterogeneous MP layer only computes embeddings for the `dst` nodes of a given `message type`."],"metadata":{"id":"0ejdkUsSDk_b"}},{"cell_type":"markdown","source":["# Heterogeneous Graph Node Property Prediction\n","\n","First let's take a look at the general structure of a heterogeneous GNN layer by working through an example:\n","\n","Let's assume we have a graph $G$, which contains two node types $a$ and $b$, and three message types $m_1=(a, r_1, a)$, $m_2=(a, r_2, b)$ and $m_3=(a, r_3, b)$. Note: during message passing we view each message as (src, relation, dst), where messages \"flow\" from src to dst node types. For example, during message passing, updating node type $b$ relies on two different message types $m_2$ and $m_3$.\n","\n","When applying message passing in heterogenous graphs, we seperately apply message passing over each message type. Therefore, for the graph $G$, a heterogeneous GNN layer contains three seperate Heterogeneous Message Passing layers (`HeteroGNNConv` in this Colab), where each `HeteroGNNConv` layer performs message passing and aggregation with respect to *only one message type*. Since a message type is viewed as (src, relation, dst) and messages \"flow\" from src to dst, each `HeteroGNNConv` layer only computes embeddings for the *dst* nodes of a given message type. For example, the `HeteroGNNConv` layer for message type $m_2$ outputs updated embedding representations *only* for node's with type b. \n","\n","---\n","\n","An overview of the heterogeneous layer we will create is shown below:\n","\n","![test](https://drive.google.com/uc?export=view&id=1mkp4OeRrvC4iNFTXSywrmI6Pfl5J__gA)\n","\n","where we highlight the following notation:\n","\n","- $H_a^{(l)[m_1]}$ is the intermediate matrix of of node embeddings for node type $a$, generated by the $l$th `HeteroGNNConv` layer for message type $m_1$.\n","- $H_a^{(l)}$ is the matrix with current embeddings for nodes of type $a$ after the $l$th layer of our Heterogeneous GNN model. Note that these embeddings can rely on one or more intermediate `HeteroGNNConv` layer embeddings(i.e. $H_b^{(l)}$ combines $H_b^{(l)[m_2]}$ and $H_b^{(l)[m_3]}$).\n","\n","Since each `HeteroGNNConv` is only applied over a single message type, we additionally define a Heterogeneous GNN Wrapper layer (`HeteroGNNWrapperConv`). This wrapper manages and combines the output of each `HeteroGNNConv` layer in order to generate the complete updated node embeddings for each node type in layer $l$ of our model.\n","\n"," More specifically, the $l^{th}$ `HeteroGNNWrapperConv` layer takes as input the node embeddings computed for each message type and node type (e.g. $H_b^{(l)[m_2]}$ and $H_b^{(l)[m_3]}$) and aggregates across message types with the same $dst$ node type. The resulting output of the $l^{th}$ `HeteroGNNWrapperConv` layer is the updated embedding matrix $H_i^{(l)}$ for each node type i. \n","\n","Continuing on our example above, to compute the node embeddings $H_b^{(l)}$ the wrapper layer aggregates output embeddings from the `HeteroGNNConv` layers associated with message types $m_2$ and $m_3$ (i.e. $H_b^{(l)[m_2]}$ and $H_b^{(l)[m_3]}$). \n","\n","---\n","\n","With the `HeteroGNNWrapperConv` module, we can now draw a \"simplified\" heterogeneous layer structure as follows:\n","\n","<br/>\n","<center>\n","<img src=\"http://web.stanford.edu/class/cs224w/images/colab4/hetero_conv_1.png\"/>\n","</center>\n","<br/>\n","\n","---\n","**NOTE**: \n","As reference, it may be helpful to additionally read through PyG's introduciton to heterogeneous graph representations and buidling heterogeneous GNN models: https://pytorch-geometric.readthedocs.io/en/latest/notes/heterogeneous.html "],"metadata":{"id":"jXIJYkxWFCnO"}},{"cell_type":"markdown","source":["# Train-test split\n","## GraphDataset\n","* dataset\n","* dataset.split(transductive=True, split_ratio)\n","    * each split return a GraphDataset object that is a list of DeepSNAP graphs"],"metadata":{"id":"jNYdyn6z6y8k"}},{"cell_type":"markdown","source":[""],"metadata":{"id":"TaOvIP55--Ny"}},{"cell_type":"code","source":["from deepsnap.dataset import GraphDataset\n","\n","dataset = GraphDataset([hete], task='node')  # hete- DeepSNAP graph\n","# Splitting the dataset\n","# returns datasets of graphs\n","dataset_train, dataset_val, dataset_test = dataset.split(transductive=True, split_ratio=[0.4, 0.3, 0.3])\n","# dataset_train[0]- dataset of first graphs\n","datasets = {'train': dataset_train, 'val': dataset_val, 'test': dataset_test}"],"metadata":{"id":"2BxKhD6E61YX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"hvds_HPN7W3a"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Module"],"metadata":{"id":"4GDSuDSgVuOi"}},{"cell_type":"markdown","source":["### forward_op(x, module_dict, **kwargs):\n","* A helper function for the heterogeneous operations. Given a dictionary input x, it will return a dictionary with the same keys and the values applied by the corresponding values of the module_dict with specified parameters. The keys in x are same with the keys in the module_dict.\n","    * x (Dict[str, Tensor]) – A dictionary that the value of each item is a tensor.\n","\n","    * module_dict (torch.nn.ModuleDict) – The value of the module_dict will be fed with each value in x.\n","\n","    * **kwargs (optional) – Parameters that will be passed into each value of the module_dict."],"metadata":{"id":"R409D9s6Vvsg"}},{"cell_type":"markdown","source":["### loss_op(pred, y, index, loss_func)\n","* A helper function for the heterogeneous loss operations. This function will sum the loss of all node types.\n","    * pred (Dict[str, Tensor]) – A dictionary of prediction results.\n","    * y (Dict[str, Tensor]) – A dictionary of labels. The keys should match with the keys in the pred.\n","    * index (Dict[str, Tensor]) – A dictionary of indicies that the loss will be computed on. Each value should be torch.LongTensor. Notice that y will not be indexed by the index. Here we assume y has been splitted into proper sets.\n","\n","    * loss_func (callable) – The defined loss function."],"metadata":{"id":"kBQYPF95CsCv"}},{"cell_type":"code","source":[""],"metadata":{"id":"C6PEVwtoV-Ow"},"execution_count":null,"outputs":[]}]}